#' Generate from a centered Laplace distribution
rlaplace <- function (n, sd = 1) {
  sample(c(-1, 1), n, replace = TRUE) * rexp(n, rate = sqrt(2) / sd)
}

#' Generate Data Using Pre-Defined Settings
#'
#' @param n number of observations.
#' @param p number of predictors.
#' @param contamination_percentage percentage of observations affected by outliers in the
#'   response and bad leverage points.
#' @param resid_dist
#' @param test_n,test_seed number of test observations and the seed for the RNG to
#'   generate these test observations.
generate_mixed_data <- function (n, p, contamination_percentage,
                                 resid_dist = 'stable(alpha = 1.5, beta = 0)',
                                 pve = 0.5,
                                 test_n = 0, test_seed = 12345) {
  settings <- list(
    n = n,
    p = p,
    s = floor(min(p - 3L, 2 * log(n))),
    cont = contamination_percentage,
    k_vert = -7,
    bad_lev_p = 0L,
    bad_lev_p_relevant = 0,
    bad_lev_pos = 4,
    good_lev_p = NA_integer_,
    good_lev_prop = 0,
    good_lev_pos = 8,
    pve = pve,
    resid_dist = resid_dist,
    pred_cor_type = 'ar1',
    pred_cor_strength = 0.5
  )

  settings$good_lev_p <- with(settings, ceiling(0.25 * min(n, (p - s))))
  rand_data <- generate_data_worker(settings, test_n, test_seed)

  ## Clustered outliers
  # k_vert_positions <- c(-4, -3, -2, -1, 5, 7)
  k_vert_positions <- c(-1, -1, -1, -0.5, -0.5, -0.5)

  max_bad_p <- ceiling(log(p))
  bad_lev_p <- sample.int(max_bad_p, min(max_bad_p, length(k_vert_positions))) - 1L
  if (max_bad_p < length(k_vert_positions)) {
    bad_lev_p <- c(bad_lev_p,
                   sample.int(max_bad_p, length(k_vert_positions) - max_bad_p, replace = TRUE) - 1L)
  }

  rle_k_vert_positions <- rep(k_vert_positions, length.out = length(rand_data$cont_ind)) |>
    sort() |>
    rle()

  rand_data$kvert_sub_groups <- cbind(
    start = c(1L, 1L + cumsum(rle_k_vert_positions$lengths[
      -length(rle_k_vert_positions$lengths)])),
    end = cumsum(rle_k_vert_positions$lengths),
    k_vert = rle_k_vert_positions$values)

  rand_data$cont_pred_bad <- list()
  rand_data$beta_cont <- list()
  rand_data$cont_pred_good <- list()

  for (i in seq_along(rand_data$kvert_sub_groups[ , 'start'])) {
    settings$bad_lev_p <- bad_lev_p[[i]]
    from <- rand_data$kvert_sub_groups[i, 'start']
    to <- rand_data$kvert_sub_groups[i, 'end']
    settings$k_vert <- rand_data$kvert_sub_groups[i, 'k_vert']
    sub_data <- generate_data_worker(settings, 0L, 0L, x = rand_data$x, y = rand_data$y)

    rand_data$y[from:to] <- sub_data$y[from:to]
    rand_data$x[from:to, ] <- sub_data$x[from:to, ]

    rand_data$beta_cont <- c(rand_data$beta_cont, list(sub_data$beta_cont))
    rand_data$cont_pred_good <- c(rand_data$cont_pred_good,
                                  list(sub_data$cont_pred_good))
    rand_data$cont_pred_bad <- c(rand_data$cont_pred_bad,
                                 list(sub_data$cont_pred_bad))
  }

  return(rand_data)
}

#' Generate Simulated Data
#'
#' The true coefficient vector is always a 0/1 vector of the form
#' `1, ..., 1, 0, ... 0` with `s` 1's and `p - s` 0's.
#' The predictors **X** are generated by a multivariate t-distribution with 4 degrees of freedom.
#'
#' The `settings` argument is a list with **all** of the the following elements:
#'  * `n` number of observations.
#'  * `p` number of predictors.
#'  * `s` number of active variables.
#'  * `cont` proportion of contamination.
#'  * `pve` percentage of variance explained.
#'  * `good_lev_p` number of predictors containing extreme values for good leverage points.
#'  * `good_lev_prop` proportion of observations with good leverage points.
#'  * `good_lev_pos` position of extreme values in good leverage points
#'                   (as a multiple of their original position).
#'  * `bad_lev_p` number of predictors containing extreme values for bad leverage points.
#'  * `bad_lev_pos` position of extreme values in bad leverage points
#'                   (as a multiple of their original position).
#'  * `k_vert` vertical outlier multiplier.
#'  * `resid_dist` distribution of the residuals. Must correspond to a valid distribution
#'                 family in R (e.g., `norm`, `cauchy`, `t(df = 5)`,
#'                 `stable(alpha = 1.33, beta = 0)`).
#'
#' @param settings data generation settings
#' @param test_n generate test data (i.e., without contamination).
#' @param test_seed the random seed to generate test data if `test_n` > 0.
#' @param x,y pre-generated x and y (optional)
#' @return a list with the predictor matrix in `x`, the response in `y` and
#'         the true regression coefficients in `beta`.
generate_data_worker <- function (settings, test_n = 0L, test_seed, x = NULL, y = NULL) {
  if (!require('Matrix', quietly = TRUE)) {
    stop("`Matrix` package is required")
  }
  if (!requireNamespace('mvnfast', quietly = TRUE)) {
    stop("`mvnfast` package is required")
  }
  if (!require('stabledist', quietly = TRUE)) {
    stop("`stabledist` package is required")
  }
  if (!requireNamespace('pense', quietly = TRUE)) {
    stop("`pense` package is required")
  }
  if (!requireNamespace('stringr', quietly = TRUE)) {
    stop("`stringr` package is required")
  }

  if (!stringr::str_detect(settings$resid_dist, stringr::fixed('('))) {
    settings$resid_dist <- paste(settings$resid_dist, '()', sep = '')
  }

  generate_resid <- function (n, sd_err) {
    # If the residual distribution is not Normal, use `pense::tau_size` for the SD function
    sdfun <- if (stringr::str_starts(settings$resid_dist, stringr::fixed('norm'))) {
      stats::sd
    } else {
      pense::tau_size
    }
    call_obj <- str2lang(paste('r', settings$resid_dist, sep = ''))
    call_obj$n <- n
    r <- eval(call_obj)

    r * sd_err / sdfun(r)
  }

  ## Generate predictors
  generate_x <- if (identical(settings$pred_cor_type, 'grouped')) {
    function (n) {
      cor_between_groups <- 0.1
      sd_perturbation <- 0.2
      group_size <- 1L + floor(.5 * sqrt(settings$p))
      n_groups <- 1L + ceiling(settings$p / group_size)

      # Generate latent variables
      j <- seq_len(settings$p)
      j_latent_map <- 1L + floor((j - 1L) / group_size) + as.integer(j > settings$s)

      # Generate latent variables
      z <- mvnfast::rmvt(n, mu = numeric(n_groups), df = 4,
                         sigma = diag(1 - cor_between_groups, n_groups) + cor_between_groups)

      # Generate the predictor matrix
      z[ , j_latent_map] + rnorm(settings$p * n, sd = sd_perturbation)
    }
  } else if (identical(settings$pred_cor_type, 'ar1')) {
    function (n) {
      chol_decomp <- vapply(seq_len(settings$p), FUN.VALUE = numeric(settings$p),
                            FUN = function (i) {
                              d <- seq_len(settings$p) - i
                              (d >= 0) * settings$pred_cor_strength^d *
                                ((i == 1) + (i > 1) * sqrt(1 - settings$pred_cor_strength^2))
                            })
      mvnfast::rmvt(n, mu = numeric(settings$p), df = 4, sigma = t(chol_decomp), isChol = TRUE)
    }
  }

  ## Define true parameter vector
  beta <- sparseVector(rep.int(1, settings$s), seq_len(settings$s), settings$p)

  ## Generate predictors
  if (missing(x) || is.null(x)) {
    x <- generate_x(settings$n)
  }

  ## Determine contamination
  ncont <- as.integer(settings$n * settings$cont)
  cont_ind <- seq_len(ncont)

  # Generate bad leverage points
  cont_pred_bad <- integer(0L)
  if (isTRUE(settings$cont > 0) &&
      isTRUE(settings$bad_lev_p > 0) &&
      isTRUE(settings$bad_lev_pos > 0)) {
    # Try not to contaminate truly active predictors, as this may artificially
    # increase sensitivity of affected estimates
    nr_cont_inactive <- with(settings, min(bad_lev_p, p - s))
    nr_cont_active <- with(settings, min(bad_lev_p_relevant, s))

    cont_pred_bad <- with(settings,
                          sort(c(sample.int(s, nr_cont_active),
                                 s + sample.int(p - s, nr_cont_inactive))))

    x_mahal <- mvnfast::maha(x[, cont_pred_bad, drop = FALSE],
                             mu = numeric(length(cont_pred_bad)),
                             sigma = cov(x[, cont_pred_bad, drop = FALSE]))

    x[cont_ind, cont_pred_bad] <- x[cont_ind, cont_pred_bad] *
      sqrt(settings$bad_lev_pos * max(x_mahal) / x_mahal[cont_ind])
  }

  if (missing(y) || is.null(y)) {
    y_model <- as.numeric(x %*% beta)

    var_regfun <- if (length(cont_ind) > 0) {
      var(y_model[-cont_ind])
    } else {
      var(y_model)
    }

    ## Determine error variance based on the given percentage of variance explained (PVE)
    sd_err <- sqrt((1 - settings$pve) * var_regfun / settings$pve)
    residuals <- generate_resid(settings$n, sd_err)

    ## Compute observed response
    y <- y_model + residuals
  } else {
    sd_err <- NA_real_
  }

  ## Add vertical outliers, i.e., outliers in the response
  beta_cont <- beta
  if (isTRUE(settings$cont > 0) && is.numeric(settings$k_vert)) {
    inds <- c(cont_pred_bad, sample.int(settings$s, 1L))
    beta_cont <- sparseVector(rep.int(settings$k_vert, length(inds)), inds, settings$p)

    # Set the SNR of the contamination to 20 (i.e., a PVE of ~95%)
    cont_y <- as.vector(x[cont_ind, ] %*% beta_cont)
    y[cont_ind] <- cont_y + rnorm(ncont, sd = sd(cont_y) / sqrt(20))
  }

  ## Introduce good leverage points in the last predictors
  if (isTRUE(settings$good_lev_prop > 0)) {
    cont_pred_good <- with(settings, rev(p - seq_len(good_lev_p)))
    x_clean_inactive <- if (length(cont_ind) > 0L) {
      x[-cont_ind, cont_pred_good, drop = FALSE]
    } else {
      x[ , cont_pred_good, drop = FALSE]
    }
    dist_rank <- rank(-mvnfast::maha(x_clean_inactive, numeric(length(cont_pred_good)),
                                     cov(x_clean_inactive)),
                      ties.method = 'first')
    good_lev_inds <- which(dist_rank <= with(settings, good_lev_prop * n))

    x_clean_inactive_ranks <- apply(abs(x_clean_inactive), 2, rank, ties.method = 'first')
    farthest_predictor <- apply(x_clean_inactive_ranks[good_lev_inds, , drop = FALSE], 1, which.max)

    if (length(cont_ind) > 0L) {
      good_lev_inds <- good_lev_inds + ncont
    }

    good_lev_cells <- (cont_pred_good[farthest_predictor] - 1L) * settings$n + good_lev_inds
    x[good_lev_cells] <- -settings$good_lev_pos * x[good_lev_cells]
  } else {
    cont_pred_good <- integer(0)
  }

  test_x <- matrix(numeric(0), nrow = 0L, ncol = settings$p)
  test_y <- numeric(0)

  if (!missing(test_n) && isTRUE(test_n > 0)) {
    # Now generate the test data -- ensuring that we don't determine the random numbers
    # generated afterwards
    reset_seed <- sample.int(.Machine$integer.max, 1L)
    set.seed(test_seed)

    test_x <- generate_x(test_n)
    test_y_model <- as.vector(test_x %*% beta)
    test_y <- test_y_model + generate_resid(test_n, sd_err)

    # Make sure the RNG will produce different results for different initial
    # seeds!
    set.seed(reset_seed)
  }

  list(x = x, y = y,
       cont_ind = cont_ind,
       clean_residuals = (y - as.numeric(x %*% beta))[-cont_ind],
       orig_residuals = residuals,
       beta = beta,
       sd_err = sd_err,
       cont_pred_bad = cont_pred_bad,
       cont_pred_good = cont_pred_good,
       beta_cont = beta_cont,
       test_data = list(x = test_x, y = test_y),
       settings = settings)
}
